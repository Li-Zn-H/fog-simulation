{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from scipy.constants import speed_of_light as c     # in m/s\n",
    "\n",
    "RNG = np.random.default_rng(seed=42)# 随机数种子\n",
    "data = np.random.normal(size=[100,5])\n",
    "print(np.mean(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class ParameterSet:# 参数集合\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        self.n = 500\n",
    "        self.n_min = 100\n",
    "        self.n_max = 1000\n",
    "\n",
    "        self.r_range = 100\n",
    "        self.r_range_min = 50\n",
    "        self.r_range_max = 250\n",
    "\n",
    "        # 衰减系数 => 雾量\n",
    "        self.alpha = 0.06\n",
    "        self.alpha_min = 0.003\n",
    "        self.alpha_max = 0.5\n",
    "        self.alpha_scale = 1000\n",
    "\n",
    "        # 气象光学范围（米）\n",
    "        self.mor = np.log(20) / self.alpha\n",
    "\n",
    "        # 向后散射系数（in 1/sr）[sr = 球面度]\n",
    "        self.beta = 0.046 / self.mor\n",
    "        self.beta_min = 0.023 / self.mor\n",
    "        self.beta_max = 0.092 / self.mor\n",
    "        self.beta_scale = 1000 * self.mor\n",
    "\n",
    "        ##########\n",
    "        # 传感器  #\n",
    "        ##########\n",
    "\n",
    "        # 脉冲峰值功率（瓦）\n",
    "        self.p_0 = 80\n",
    "        self.p_0_min = 60\n",
    "        self.p_0_max = 100\n",
    "\n",
    "        # 半功率脉冲宽度（秒）\n",
    "        self.tau_h = 2e-8\n",
    "        self.tau_h_min = 5e-9\n",
    "        self.tau_h_max = 8e-8\n",
    "        self.tau_h_scale = 1e9\n",
    "\n",
    "        # 总脉冲能力（焦）\n",
    "        self.e_p = self.p_0 * self.tau_h  # equation (7) in [1]\n",
    "\n",
    "        # 接收器孔径面积（米）\n",
    "        self.a_r = 0.25\n",
    "        self.a_r_min = 0.01\n",
    "        self.a_r_max = 0.1\n",
    "        self.a_r_scale = 1000\n",
    "\n",
    "        # 接收器光学损失\n",
    "        self.l_r = 0.05\n",
    "        self.l_r_min = 0.01\n",
    "        self.l_r_max = 0.10\n",
    "        self.l_r_scale = 100\n",
    "\n",
    "        self.c_a = c * self.l_r * self.a_r / 2\n",
    "\n",
    "        self.linear_xsi = True\n",
    "\n",
    "        self.D = 0.1                                    #  发射器和接收器的位移 米\n",
    "        self.ROH_T = 0.01                               #  发射器孔径半径 米\n",
    "        self.ROH_R = 0.01                               #  接收器孔径半径 米\n",
    "        self.GAMMA_T_DEG = 2                            #  发射器视野的开启角度 角度\n",
    "        self.GAMMA_R_DEG = 3.5                          #  接收器事业的开启角度 角度\n",
    "        self.GAMMA_T = math.radians(self.GAMMA_T_DEG)\n",
    "        self.GAMMA_R = math.radians(self.GAMMA_R_DEG)\n",
    "\n",
    "        # 接收器视场开始覆盖发射波束的范围（米）\n",
    "        self.r_1 = 0.9\n",
    "        self.r_1_min = 0\n",
    "        self.r_1_max = 10\n",
    "        self.r_1_scale = 10\n",
    "\n",
    "        # 接收器视场完全覆盖发射波束的范围（m）\n",
    "        self.r_2 = 1.0\n",
    "        self.r_2_min = 0\n",
    "        self.r_2_max = 10\n",
    "        self.r_2_scale = 10\n",
    "\n",
    "        ###############\n",
    "        #    硬目标    #\n",
    "        ###############\n",
    "\n",
    "        # 到硬目标的距离（m）\n",
    "        self.r_0 = 30\n",
    "        self.r_0_min = 1\n",
    "        self.r_0_max = 200\n",
    "\n",
    "        # 硬目标的反射率[0.07，0.2， > 4 = > 低，正常，高]\n",
    "        self.gamma = 0.000001\n",
    "        self.gamma_min = 0.0000001\n",
    "        self.gamma_max = 0.00001\n",
    "        self.gamma_scale = 10000000\n",
    "\n",
    "        # 目标的微分反射率\n",
    "        self.beta_0 = self.gamma / np.pi\n",
    "        self.__dict__.update(kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_available_alphas() -> List[float]:# 得到所有文件的阿尔法值参数\n",
    "\n",
    "    alphas = []\n",
    "\n",
    "    # for file in os.listdir(INTEGRAL_PATH):# 返回指定的文件夹包含的文件或文件夹的名字的列表。\n",
    "    #     # print(file)\n",
    "    #     if file.endswith(\".pickle\"):\n",
    "    #         alpha = file.split('_')[-1].replace('.pickle', '')\n",
    "    #         alphas.append(float(alpha))\n",
    "    alphas.append(0.005)\n",
    "    return sorted(alphas)#排序"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def P_R_fog_hard(p: ParameterSet, pc: np.ndarray) -> np.ndarray:\n",
    "    r_0 = np.linalg.norm(pc[:, 0:3], axis=1)#求行范数\n",
    "    pc[:, 3] = np.round(np.exp(-2 * p.alpha * r_0) * pc[:, 3])#e^-2*α*r0 * i\n",
    "    return pc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def P_R_fog_soft(p: ParameterSet, pc: np.ndarray, original_intesity: np.ndarray, noise: int, gain: bool = False,\n",
    "                 noise_variant: str = 'v1') -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "\n",
    "    augmented_pc = np.zeros(pc.shape)\n",
    "    fog_mask = np.zeros(len(pc), dtype=bool)\n",
    "\n",
    "    r_zeros = np.linalg.norm(pc[:, 0:3], axis=1)\n",
    "\n",
    "    min_fog_response = np.inf\n",
    "    max_fog_response = 0\n",
    "    num_fog_responses = 0\n",
    "\n",
    "    # integral_dict = get_integral_dict(p)\n",
    "\n",
    "    r_noise = RNG.integers(low=1, high=20, size=1)[0]\n",
    "    r_noise = 10\n",
    "\n",
    "    for i, r_0 in enumerate(r_zeros):\n",
    "\n",
    "        # load integral values from precomputed dict\n",
    "        key = float(str(round(r_0, 1)))\n",
    "        # limit key to a maximum of 200 m\n",
    "        fog_distance, fog_response = integral_dict[min(key, 200)]\n",
    "\n",
    "        fog_response = fog_response * original_intesity[i] * (r_0 ** 2) * p.beta / p.beta_0\n",
    "\n",
    "        # limit to 255\n",
    "        fog_response = min(fog_response, 255)\n",
    "\n",
    "        if fog_response > pc[i, 3]:\n",
    "\n",
    "            fog_mask[i] = 1\n",
    "\n",
    "            num_fog_responses += 1\n",
    "\n",
    "            scaling_factor = fog_distance / r_0\n",
    "\n",
    "            augmented_pc[i, 0] = pc[i, 0] * scaling_factor\n",
    "            augmented_pc[i, 1] = pc[i, 1] * scaling_factor\n",
    "            augmented_pc[i, 2] = pc[i, 2] * scaling_factor\n",
    "            augmented_pc[i, 3] = fog_response\n",
    "\n",
    "            # keep 5th feature if it exists\n",
    "            if pc.shape[1] > 4:\n",
    "                augmented_pc[i, 4] = pc[i, 4]\n",
    "\n",
    "            if noise > 0:\n",
    "\n",
    "                if noise_variant == 'v1':\n",
    "\n",
    "                    # add uniform noise based on initial distance\n",
    "                    distance_noise = RNG.uniform(low=r_0 - noise, high=r_0 + noise, size=1)[0]\n",
    "                    noise_factor = r_0 / distance_noise\n",
    "\n",
    "                elif noise_variant == 'v2':\n",
    "\n",
    "                    # add noise in the power domain\n",
    "                    power = RNG.uniform(low=-1, high=1, size=1)[0]\n",
    "                    noise_factor = max(1.0, noise/5) ** power       # noise=10 => noise_factor ranges from 1/2 to 2\n",
    "\n",
    "                elif noise_variant == 'v3':\n",
    "\n",
    "                    # add noise in the power domain\n",
    "                    power = RNG.uniform(low=-0.5, high=1, size=1)[0]\n",
    "                    noise_factor = max(1.0, noise*4/10) ** power    # noise=10 => ranges from 1/2 to 4\n",
    "\n",
    "                elif noise_variant == 'v4':\n",
    "\n",
    "                    additive = r_noise * RNG.beta(a=2, b=20, size=1)[0]\n",
    "                    new_dist = fog_distance + additive\n",
    "                    noise_factor = new_dist / fog_distance\n",
    "\n",
    "                else:\n",
    "\n",
    "                    raise NotImplementedError(f\"noise variant '{noise_variant}' is not implemented (yet)\")\n",
    "\n",
    "                augmented_pc[i, 0] = augmented_pc[i, 0] * noise_factor\n",
    "                augmented_pc[i, 1] = augmented_pc[i, 1] * noise_factor\n",
    "                augmented_pc[i, 2] = augmented_pc[i, 2] * noise_factor\n",
    "\n",
    "            if fog_response > max_fog_response:\n",
    "                max_fog_response = fog_response\n",
    "\n",
    "            if fog_response < min_fog_response:\n",
    "                min_fog_response = fog_response\n",
    "\n",
    "        else:\n",
    "\n",
    "            augmented_pc[i] = pc[i]\n",
    "\n",
    "    if gain:\n",
    "        max_intensity = np.ceil(max(augmented_pc[:, 3]))\n",
    "        gain_factor = 255 / max_intensity\n",
    "        augmented_pc[:, 3] *= gain_factor\n",
    "\n",
    "    simulated_fog_pc = None\n",
    "\n",
    "    if num_fog_responses > 0:\n",
    "        fog_points = augmented_pc[fog_mask]\n",
    "        simulated_fog_pc = fog_points\n",
    "\n",
    "    info_dict = {'min_fog_response': min_fog_response,\n",
    "                 'max_fog_response': max_fog_response,\n",
    "                 'num_fog_responses': num_fog_responses}\n",
    "\n",
    "    return augmented_pc, simulated_fog_pc, info_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def simulate_fog(p: ParameterSet, pc: np.ndarray, noise: int, gain: bool = False, noise_variant: str = 'v1',\n",
    "                 hard: bool = True, soft: bool = True) -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "\n",
    "    augmented_pc = copy.deepcopy(pc)\n",
    "    original_intensity = copy.deepcopy(pc[:, 3])\n",
    "\n",
    "    info_dict = None\n",
    "    simulated_fog_pc = None\n",
    "\n",
    "    if hard:\n",
    "        augmented_pc = P_R_fog_hard(p, augmented_pc)\n",
    "    if soft:\n",
    "        augmented_pc, simulated_fog_pc, info_dict = P_R_fog_soft(p, augmented_pc, original_intensity, noise, gain,\n",
    "                                                                 noise_variant)\n",
    "\n",
    "    return augmented_pc, simulated_fog_pc, info_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def parse_arguments():# 解析参数\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='LiDAR foggification')# 解析器：将命令行解析成Python数据类型\n",
    "\n",
    "    parser.add_argument('-c', '--n_cpus', help='number of CPUs that should be used', type=int, default=mp.cpu_count())# 添加参数 cpu内核数\n",
    "    parser.add_argument('-f', '--n_features', help='number of point features', type=int, default=5)# 添加参数 点云特帧数\n",
    "    parser.add_argument('-r', '--root_folder', help='root folder of dataset',\n",
    "                        default=str(Path.home() / 'datasets/DENSE/SeeingThroughFog'))# 添加参数 根目录\n",
    "\n",
    "    arguments = parser.parse_args()\n",
    "\n",
    "    return arguments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # args = parse_arguments()# 命名空间\n",
    "    # print(f'using {args.n_cpus} CPUs') #打印使用的CPU内核数\n",
    "\n",
    "    available_alphas = get_available_alphas()#得到文件的阿尔法参数\n",
    "\n",
    "    # for lidar_folder in LIDAR_FOLDERS:#遍历传感器文件夹\n",
    "    #     src_folder = os.path.join(args.root_folder, lidar_folder)#链接两个文件夹获取数据集\n",
    "    #     print(src_folder)\n",
    "    #     all_files = []\n",
    "    #\n",
    "    #     for root, dirs, files in os.walk(src_folder, followlinks=True):#目录遍历器\n",
    "    #         assert (root == src_folder)#表达式位错出发异常\n",
    "    #         all_files = sorted(files)#添加文件\n",
    "    #\n",
    "    #     all_paths = [os.path.join(src_folder, file) for file in all_files]#添加所有路径\n",
    "    #\n",
    "    #     for available_alpha in available_alphas:#遍历所有参数\n",
    "    #\n",
    "    #         dst_folder = f'{src_folder}_CVL_beta_{available_alpha:.3f}'#遍历数据集\n",
    "    #         # print(dst_folder)\n",
    "    for i in range(1):\n",
    "        # Path(dst_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # print('')\n",
    "        # print(f'alpha {available_alpha}')\n",
    "        # print('')\n",
    "        # print(f'searching for point clouds in    {src_folder}')\n",
    "        # print(f'saving augmented point clouds to {dst_folder}')\n",
    "\n",
    "        # parameter_set = ParameterSet(alpha=available_alpha, gamma=0.000001)\n",
    "        parameter_set = ParameterSet(alpha=available_alphas[0], gamma=0.000001)\n",
    "\n",
    "        def _map(i: int) -> None:\n",
    "\n",
    "            # points = np.fromfile(all_paths[i], dtype=np.float32)#以float32读取所有数据\n",
    "            points = data\n",
    "            # points = points.reshape((-1, args.n_features))#将所有点转成直线\n",
    "            points = points.reshape((-1, 5))#将所有点转成直线\n",
    "\n",
    "            points, _, _ = simulate_fog(parameter_set, points, 10)\n",
    "\n",
    "            # lidar_save_path = os.path.join(dst_folder, all_files[i])#保存文件夹\n",
    "            # points.astype(np.float32).tofile(lidar_save_path)\n",
    "\n",
    "        # n = len(all_files)\n",
    "        n = 8\n",
    "        # with mp.Pool(args.n_cpus) as pool:#多进程\n",
    "        # with mp.Pool(8) as pool:#多进程\n",
    "            # l = list(tqdm(pool.imap(_map, range(n)), total=n))#进度条"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}